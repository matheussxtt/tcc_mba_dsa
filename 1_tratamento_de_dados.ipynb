{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando os Dados - Base de Ausências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasta de referência para salvamento dos arquivos\n",
    "path_input = Path(r\"C:\\Users\\Matheus\\Desktop\\codigo_mba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Baixar os dados\n",
    "# Função para gerar strings de mes-ano de 1018 até 0424 (formato MMYY)\n",
    "def generate_month_year_range(start, end):\n",
    "    start_date = datetime.strptime(start, \"%m%y\")\n",
    "    end_date = datetime.strptime(end, \"%m%y\")\n",
    "    date_generated = [start_date + timedelta(days=30*i) for i in range((end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1)]\n",
    "    return [date.strftime(\"%m%y\") for date in date_generated]\n",
    "\n",
    "# Nome da pasta na qual os arquivos serão salvos\n",
    "folder_name = \"base\"\n",
    "folder_path = path_input / folder_name\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Data de início e fim do período de coleta - optei por pegar grande parte dos dados disponíveis \n",
    "start_date = \"1018\"\n",
    "end_date = \"0424\"\n",
    "\n",
    "# Gera uma lista de datas a partir das strings de data\n",
    "dates = generate_month_year_range(start_date, end_date)\n",
    "\n",
    "# Itera sobre as datas e faz requisições para o site da prefeitura da educação, extraindo os dados\n",
    "for date in dates:\n",
    "    url = f'https://dados.educacao.sp.gov.br/sites/default/files/%5Bdbo%5D.%5BBASE_AUSENCIAS_{date}%5D.csv'\n",
    "    response = requests.get(url, verify=False)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        file_path = os.path.join(folder_path, f'[dbo].[BASE_AUSENCIAS_{date}].csv')\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f'Arquivo extraido para {file_path}')\n",
    "    else:\n",
    "        print(f'Falha na extração do arquivo {date}. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renomeando as Tabelas - Base de Ausências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Renomear os csvs\n",
    "# Diretório no qual as tabelas estão armazenadas, caso não seja a mesma onde os dados foram baixados, ajustar\n",
    "directory = folder_path\n",
    "\n",
    "# Regex para encontar o nopme bruto do arquivo\n",
    "pattern = re.compile(r'\\[dbo\\]\\.\\[BASE_AUSENCIAS_(\\d{4})\\]')\n",
    "\n",
    "# Itera sobre os nomes e trata eles, de forma que eles fiquem mais claros em relação ao período de referencia\n",
    "for filename in os.listdir(directory):\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        date_part = match.group(1)\n",
    "        new_filename = f'ausencias_{date_part}.csv'\n",
    "        old_file = os.path.join(directory, filename)\n",
    "        new_file = os.path.join(directory, new_filename)\n",
    "        os.rename(old_file, new_file)\n",
    "        print(f'Arquivo: {old_file} renomeado para {new_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando os anos em pastas distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os anos em pastas distintas\n",
    "# Lista de anos para separar os dados\n",
    "years = ['2019', '2020', '2021', '2022', '2023']\n",
    "\n",
    "# Cria uma pasta para cada ano\n",
    "for year in years:\n",
    "    year_folder = os.path.join(directory, year)\n",
    "    os.makedirs(year_folder, exist_ok=True)\n",
    "\n",
    "# Move os arquivos para as pastas específicas, com base no ano ao qual eles se referem\n",
    "for filename in os.listdir(directory):\n",
    "    print(filename)\n",
    "    if filename.startswith('ausencias_') and filename.endswith('.csv'):\n",
    "        date_part = filename.split('_')[1].split('.')[0]\n",
    "        year = f'20{date_part[2:4]}'\n",
    "        if year in years:\n",
    "            old_file = os.path.join(directory, filename)\n",
    "            target_folder = os.path.join(directory, year)\n",
    "            shutil.move(old_file, target_folder)\n",
    "            print(f'Arquivo: {old_file} movido para {target_folder}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinando os CSVs com base nos anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agora vamos combinar os arquivos para cada ano \n",
    "#Lista de anos (igual a pasta de anos)\n",
    "years = ['2019','2020', '2021', '2022', '2023']\n",
    "\n",
    "#Itera sobre cada pasta e cria arquivos unificados de ausências, adicionando uma coluna adicional que se refere ao mês do arquivo original\n",
    "for year in years:\n",
    "    year_folder = os.path.join(directory,year)\n",
    "    dataframes = []\n",
    "    for filename in os.listdir(year_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(year_folder, filename)\n",
    "            mmyy = filename.split('_')[1].split('.')[0]\n",
    "            date_obj = datetime.strptime(mmyy, '%m%y')\n",
    "            df = pd.read_csv(file_path,sep=';')\n",
    "            df['mes'] = date_obj\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatena os dataframes por ano\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Salva os arquivos unificados na pasta de seus respectivos anos\n",
    "    combined_df.to_excel(os.path.join(year_folder, f'{year}_combined_data.csv'), index=False)\n",
    "\n",
    "    print(f'Arquivos concatenados salvos em {os.path.join(year_folder, \"combined_data.csv\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprimindo as bases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Os arquivos originais são muito grandes, por conta de possuirem valores muito granulares (a nível de escola). Vamos somar os valores por município e por mes\n",
    "\n",
    "folder_name = \"base/bases_agregadas/bases_granulares_mes\"\n",
    "aggregated_data_folder = path_input / folder_name\n",
    "\n",
    "\n",
    "for filename in os.listdir(aggregated_data_folder):\n",
    "    year = filename.split('_')[0]\n",
    "    \n",
    "\n",
    "    file_path = os.path.join(aggregated_data_folder, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['municipio'] = df['MUNICIPIO_EXERC'].apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "    # Colunas de faltas a serem somadas\n",
    "    columns_to_sum = [\n",
    "        'TT_DIAS_FALTA_MEDICA', 'TT_DIAS_FALTA_JUST', 'TT_DIAS_FALTA_INJUST', \n",
    "        'TT_DIAS_LIC_PREMIO', 'TT_DIAS_LIC_GESTANTE', 'TT_DIAS_LIC_ACID_TRAB', \n",
    "        'TT_DIAS_LIC_INTER_PARTIC'\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    # Os dados serão agrupados pelo nome do município e por mes, para então calcularmos o tipo de fala.\n",
    "    grouped_df = df.groupby(['municipio','mes'])[columns_to_sum].sum().reset_index()\n",
    "\n",
    "    grouped_df.to_csv(os.path.join(aggregated_data_folder, f'{year}_agg_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando os Dados - Base de Servidores Ativos\n",
    "\n",
    "Vamos precisar repetir o processo para extrair a quantidade de servidores ativos por município, o código é similar ao de cima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Baixar os dados\n",
    "def generate_month_year_range(start, end):\n",
    "    start_date = datetime.strptime(start, \"%m%y\")\n",
    "    end_date = datetime.strptime(end, \"%m%y\")\n",
    "    date_generated = [start_date + timedelta(days=30*i) for i in range((end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1)]\n",
    "    return [date.strftime(\"%m%y\") for date in date_generated]\n",
    "\n",
    "# Cria uma pasta com base no primeiro nome fornecido\n",
    "folder_name = \"base_servidores_ativos\"\n",
    "folder_path = path_input / folder_name\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "\n",
    "\n",
    "# Data de início e fim do período de coleta - optei por pegar grande parte dos dados disponíveis \n",
    "start_date = \"1018\"\n",
    "end_date = \"0424\"\n",
    "\n",
    "# Gera uma lista de datas a partir das strings de data\n",
    "dates = generate_month_year_range(start_date, end_date)\n",
    "\n",
    "# Itera sobre as datas e faz requisições para o site da prefeitura da educação, extraindo os dados\n",
    "for date in dates:\n",
    "    url = f'https://dados.educacao.sp.gov.br/sites/default/files/%5Bdbo%5D.%5BBASE_SERVIDORES_ATIVOS_{date}%5D.csv'\n",
    "    response = requests.get(url, verify=False)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        file_path = os.path.join(folder_path, f'servidores_{date}.csv')\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f'Arquivo extraido para {file_path}')\n",
    "    else:\n",
    "        print(f'Falha na extração do arquivo {date}. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando os anos em pastas distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os anos em pastas distintas\n",
    "# Lista de anos para separar os dados\n",
    "years = ['2019', '2020', '2021', '2022', '2023']\n",
    "\n",
    "\n",
    "directory =  folder_path\n",
    "\n",
    "# pastas para cada ano\n",
    "for year in years:\n",
    "    year_folder = os.path.join(directory, year)\n",
    "    os.makedirs(year_folder, exist_ok=True)\n",
    "\n",
    "# Itera sobre os arquivos e os move para pastas distintas, com base em seus anos\n",
    "for filename in os.listdir(directory):\n",
    "    print(filename)\n",
    "    if filename.startswith('servidores_') and filename.endswith('.csv'):\n",
    "        date_part = filename.split('_')[1].split('.')[0]\n",
    "        year = f'20{date_part[2:4]}'\n",
    "        if year in years:\n",
    "            old_file = os.path.join(directory, filename)\n",
    "            target_folder = os.path.join(directory, year)\n",
    "            shutil.move(old_file, target_folder)\n",
    "            print(f'Moved: {old_file} to {target_folder}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinando os CSVs com base nos anos\n",
    "\n",
    "De maneira similar aos dados de ausência, vamos agregar os dados por mês e municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "years = ['2019','2020', '2021', '2022', '2023']\n",
    "directory =  folder_path\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    year_folder = os.path.join(directory,year)\n",
    "    dataframes = []\n",
    "    for filename in os.listdir(year_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "\n",
    "            file_path = os.path.join(year_folder, filename)\n",
    "            print(file_path)\n",
    "            mmyy = filename.split('_')[1].split('.')[0]\n",
    "            \n",
    "            date_obj = datetime.strptime(mmyy, '%m%y')\n",
    "            \n",
    "            df = pd.read_csv(file_path,sep=';')\n",
    "            subset_df = df[['MUNICIPIO_E','ID_INTERNO']].copy()\n",
    "                        \n",
    "            subset_df_deduped =  subset_df.drop_duplicates(subset=['MUNICIPIO_E', 'ID_INTERNO']).rename(columns={\n",
    "                                                                                                                    'MUNICIPIO_E': 'municipio',\n",
    "                                                                                                                    'ID_INTERNO':'id_interno'\n",
    "                                                                                                                    })\n",
    "            dataframes.append(subset_df_deduped)\n",
    "\n",
    "\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    combined_df_agg = combined_df['municipio'].value_counts().reset_index()\n",
    "    combined_df_agg['ano'] = year\n",
    "    combined_df_agg.to_excel(os.path.join(year_folder, f'{year}_combined_data.xlsx'), index=False)\n",
    "\n",
    "    print(f'Dataframe concatenado slavo em {os.path.join(year_folder, \"combined_data.csv\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
